<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>3D Model in Camera</title>
  <style>
    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
    }
    #cameraFeed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }
    #threeCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1;
      pointer-events: none;
    }
    #openBtn {
      position: absolute;
      top: 20px;
      left: 20px;
      z-index: 2;
      padding: 10px 20px;
      background: purple;
      color: white;
      border: none;
      border-radius: 8px;
      font-size: 16px;
    }
    #captureBtn {
      position: absolute;
      top: 20px;
      left: 150px;
      z-index: 2;
      padding: 10px 20px;
      background: #4CAF50;
      color: white;
      border: none;
      border-radius: 8px;
      font-size: 16px;
      display: none;
    }
    #resultText {
      position: absolute;
      top: 80px;
      left: 20px;
      z-index: 2;
      color: white;
      font-size: 24px;
      font-weight: bold;
      text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5);
      display: none;
    }
  </style>
  <!-- Load Three.js and its dependencies -->
  <script src="/static/js/three.min.js"></script>
  <script src="/static/js/GLTFLoader.js"></script>
  <!-- Add MediaPipe hand tracking -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js"></script>
</head>
<body>
  <video id="cameraFeed" autoplay muted playsinline></video>
  <canvas id="threeCanvas"></canvas>
  <button id="openBtn">Open Camera</button>
  <button id="captureBtn">Take Photo</button>
  <div id="resultText"></div>

  <script>
    // Wait for Three.js to load
    window.addEventListener('load', function() {
      console.log('Three.js loaded:', typeof THREE !== 'undefined');
      
      const video = document.getElementById('cameraFeed');
      const canvas = document.getElementById('threeCanvas');
      const openBtn = document.getElementById('openBtn');
      const captureBtn = document.getElementById('captureBtn');
      const resultText = document.getElementById('resultText');
      
      const GEMINI_API_KEY = 'AIzaSyBHVWfY-js7KnjSQGuRe_Q0S2Tfu6W_cLI';
      
      let scene, camera, renderer, model;
      let hands;
      let lastPinchDistance = 0;
      let lastHandPosition = null;
      let targetZoom = 3;
      let targetRotation = { x: 0, y: 0 };
      const minZoom = 2.0;
      const maxZoom = 6.0;
      const zoomSpeed = 0.1;
      const zoomInterpolationFactor = 0.08;
      const rotationInterpolationFactor = 0.1;
      const rotationSensitivity = 3.0;
      let isHandTrackingActive = false;
      
      // Add label containers
      let labels = [];
      let labelContainer;
      
      // Add smoothing buffers
      const positionBuffer = [];
      const rotationBuffer = [];
      const bufferSize = 3;
      const movementThreshold = 0.005;

      // Add mouse control variables
      let isMouseDown = false;
      let lastMouseX = 0;
      let lastMouseY = 0;
      let mouseSensitivity = 0.01;
      let mouseZoomSpeed = 0.1;

      // Function to capture model view
      function captureModelView(angle) {
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = 800;
        tempCanvas.height = 600;
        const tempRenderer = new THREE.WebGLRenderer({ 
          canvas: tempCanvas,
          alpha: true,
          antialias: true
        });
        
        // Create temporary camera
        const tempCamera = new THREE.PerspectiveCamera(75, 800/600, 0.1, 1000);
        tempCamera.position.set(0, 0, 5);
        
        // Rotate model for the view
        const originalRotation = model.rotation.clone();
        model.rotation.set(0, angle * Math.PI / 180, 0);
        
        // Render the view
        tempRenderer.render(scene, tempCamera);
        
        // Reset model rotation
        model.rotation.copy(originalRotation);
        
        return tempCanvas.toDataURL('image/jpeg');
      }

      // Function to create text label with simplified styling
      function createTextLabel(text, position, color = 0x000000) {
        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        canvas.width = 300;
        canvas.height = 80;
        
        // Simple background
        context.fillStyle = 'rgba(0, 0, 0, 0.5)';
        context.fillRect(0, 0, canvas.width, canvas.height);
        
        // Simple text styling
        context.font = '20px Arial';
        context.fillStyle = '#ffffff';
        context.textAlign = 'left';
        context.fillText(text, 15, canvas.height/2 + 10);
        
        const texture = new THREE.CanvasTexture(canvas);
        const material = new THREE.SpriteMaterial({ 
          map: texture,
          transparent: true,
          opacity: 0.8
        });
        const sprite = new THREE.Sprite(material);
        
        sprite.position.copy(position);
        sprite.scale.set(1.2, 0.3, 1);
        sprite.userData = { 
          text: text,
          originalColor: color
        };
        
        return sprite;
      }

      // Function to create connecting line with simplified styling
      function createConnectingLine(start, end, color = 0x000000) {
        const material = new THREE.LineBasicMaterial({ 
          color: color,
          linewidth: 3,
          transparent: true,
          opacity: 0.8
        });
        const points = [];
        points.push(start);
        points.push(end);
        const geometry = new THREE.BufferGeometry().setFromPoints(points);
        const line = new THREE.Line(geometry, material);
        return line;
      }

      // Function to analyze model views
      async function analyzeModelViews() {
        try {
          // Capture front and side views
          const frontView = captureModelView(0);
          const sideView = captureModelView(90);
          
          // Prepare the request to Gemini API
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [{
                parts: [
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: frontView.split(',')[1]
                    }
                  },
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: sideView.split(',')[1]
                    }
                  },
                  {
                    text: "These are front and side views of a 3D brain model. Analyze the brain structure and provide 5-6 labels describing different parts of the brain. For each label, specify its position in degrees (0-360) around the model. Return ONLY a valid JSON object in this exact format: {\"labels\": [{\"text\": \"label name\", \"angle\": \"angle in degrees\"}, ...]}. Do not include any other text or explanation."
                  }
                ]
              }]
            })
          });
          
          const data = await response.json();
          if (data.candidates && data.candidates[0].content.parts[0].text) {
            const result = data.candidates[0].content.parts[0].text;
            try {
              // Clean the response to ensure it's valid JSON
              const jsonStart = result.indexOf('{');
              const jsonEnd = result.lastIndexOf('}') + 1;
              const jsonStr = result.substring(jsonStart, jsonEnd);
              
              const labelsData = JSON.parse(jsonStr).labels;
              create3DLabels(labelsData);
            } catch (e) {
              console.error('Error parsing labels:', e);
              console.log('Raw response:', result);
            }
          }
        } catch (error) {
          console.error('Error analyzing model views:', error);
        }
      }

      // Initialize MediaPipe Hands
      function initHandTracking() {
        console.log('Initializing hand tracking...');
        hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/${file}`;
          }
        });
        
        hands.setOptions({
          maxNumHands: 1,  // Changed to 1 hand for better focus
          modelComplexity: 0,  // Changed to 0 for faster processing
          minDetectionConfidence: 0.7,  // Increased confidence threshold
          minTrackingConfidence: 0.7    // Increased confidence threshold
        });

        hands.onResults(onHandResults);
        console.log('Hand tracking initialized');
      }

      // Process hand tracking results with enhanced zoom
      function onHandResults(results) {
        if (!results.multiHandLandmarks) {
          if (isHandTrackingActive) {
            console.log('Hand lost, maintaining last position');
            isHandTrackingActive = false;
          }
          return;
        }

        if (!model) {
          console.log('Model not loaded yet');
          return;
        }

        isHandTrackingActive = true;
        const landmarks = results.multiHandLandmarks[0];
        
        if (landmarks) {
          const thumbTip = landmarks[4];
          const indexTip = landmarks[8];
          const palmBase = landmarks[0];
          
          // Enhanced pinch zoom with better sensitivity
          const pinchDistance = Math.sqrt(
            Math.pow(thumbTip.x - indexTip.x, 2) +
            Math.pow(thumbTip.y - indexTip.y, 2)
          );

          if (lastPinchDistance === 0) {
            lastPinchDistance = pinchDistance;
            lastHandPosition = { x: palmBase.x, y: palmBase.y };
            return;
          }

          // Calculate zoom factor with enhanced sensitivity
          const zoomFactor = lastPinchDistance / pinchDistance;
          if (Math.abs(1 - zoomFactor) > 0.03) {  // Reduced threshold for more responsive zoom
            const newTargetZoom = camera.position.z * zoomFactor;
            targetZoom = Math.max(minZoom, Math.min(maxZoom, newTargetZoom));
          }
          lastPinchDistance = pinchDistance;

          // Handle hand rotation with smoothing
          if (lastHandPosition) {
            // Calculate hand movement delta with increased sensitivity
            const deltaX = (palmBase.x - lastHandPosition.x) * rotationSensitivity;
            const deltaY = (palmBase.y - lastHandPosition.y) * rotationSensitivity;

            // Only update if movement is significant
            if (Math.abs(deltaX) > movementThreshold || Math.abs(deltaY) > movementThreshold) {
              // Add to rotation buffer
              rotationBuffer.push({ x: deltaX, y: deltaY });
              if (rotationBuffer.length > bufferSize) {
                rotationBuffer.shift();
              }

              // Calculate average rotation with reduced smoothing
              const avgRotation = rotationBuffer.reduce((acc, curr) => {
                return { x: acc.x + curr.x, y: acc.y + curr.y };
              }, { x: 0, y: 0 });
              
              const avgDeltaX = avgRotation.x / rotationBuffer.length;
              const avgDeltaY = avgRotation.y / rotationBuffer.length;

              // Update target rotation with increased movement
              targetRotation.y += avgDeltaX * 1.5;  // Increased rotation multiplier
              targetRotation.x += avgDeltaY * 1.5;  // Increased rotation multiplier

              // Clamp rotation to reasonable bounds
              targetRotation.x = Math.max(-Math.PI/2, Math.min(Math.PI/2, targetRotation.x));
              targetRotation.y = Math.max(-Math.PI, Math.min(Math.PI, targetRotation.y));
            }
          }

          lastHandPosition = { x: palmBase.x, y: palmBase.y };
        }
      }

      // Function to capture photo and send to Gemini
      async function captureAndAnalyze() {
        try {
          // Create a temporary canvas to capture the video frame
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          const ctx = tempCanvas.getContext('2d');
          ctx.drawImage(video, 0, 0);
          
          // Convert canvas to base64
          const imageData = tempCanvas.toDataURL('image/jpeg');
          
          // Prepare the request to Gemini API
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [{
                parts: [
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: imageData.split(',')[1]
                    }
                  },
                  {
                    text: "Identify the main object in this image with a single word."
                  }
                ]
              }]
            })
          });
          
          const data = await response.json();
          if (data.candidates && data.candidates[0].content.parts[0].text) {
            const result = data.candidates[0].content.parts[0].text;
            resultText.textContent = result;
            resultText.style.display = 'block';
          }
        } catch (error) {
          console.error('Error analyzing image:', error);
          resultText.textContent = 'Error analyzing image';
          resultText.style.display = 'block';
        }
      }

      // Initialize the camera feed
      async function initCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: 640,
              height: 480,
              facingMode: 'user'
            } 
          });
          video.srcObject = stream;
          
          // Wait for video to be ready
          video.onloadedmetadata = () => {
            console.log('Video stream ready');
            // Show capture button
            captureBtn.style.display = 'block';
            // Initialize hand tracking after camera is ready
            initHandTracking();
            
            // Start sending frames to MediaPipe
            const camera = new Camera(video, {
              onFrame: async () => {
                try {
                  await hands.send({ image: video });
                } catch (error) {
                  console.error('Error processing hand tracking:', error);
                }
              },
              width: 640,
              height: 480
            });
            camera.start();
            console.log('Camera tracking started');
          };
        } catch (err) {
          console.error('Camera error:', err);
        }
      }

      // Function to create arrow helper
      function createArrowHelper(start, end, color = 0xffffff) {
        const dir = new THREE.Vector3().subVectors(end, start).normalize();
        const length = start.distanceTo(end);
        const arrowHelper = new THREE.ArrowHelper(dir, start, length, color, length * 0.2, length * 0.1);
        return arrowHelper;
      }

      // Function to create 3D labels based on analysis
      function create3DLabels(labelsData) {
        if (!model) return;
        
        // Remove existing labels
        if (labelContainer) {
          scene.remove(labelContainer);
        }
        
        labelContainer = new THREE.Group();
        
        // Get model bounding box
        const box = new THREE.Box3().setFromObject(model);
        const size = box.getSize(new THREE.Vector3());
        const center = box.getCenter(new THREE.Vector3());
        
        // Define label positions around the model
        const radius = size.x * 1.2;  // Distance from center
        
        // Create labels and connecting lines based on the analyzed data
        labelsData.forEach(label => {
          // Calculate position around the model
          const angleRad = parseFloat(label.angle) * Math.PI / 180;
          const x = center.x + radius * Math.cos(angleRad);
          const z = center.z + radius * Math.sin(angleRad);
          const y = center.y;  // Default height, can be adjusted based on model
          
          const labelPosition = new THREE.Vector3(x, y, z);
          const targetPosition = new THREE.Vector3(
            center.x + size.x * 0.3 * Math.cos(angleRad),
            y,
            center.z + size.z * 0.3 * Math.sin(angleRad)
          );
          
          // Create text label
          const textLabel = createTextLabel(label.text, labelPosition);
          labelContainer.add(textLabel);
          
          // Create connecting line
          const line = createConnectingLine(targetPosition, labelPosition);
          labelContainer.add(line);
          
          // Add small circle at the model connection point
          const circleGeometry = new THREE.CircleGeometry(0.05, 32);
          const circleMaterial = new THREE.MeshBasicMaterial({ color: 0x000000 });
          const circle = new THREE.Mesh(circleGeometry, circleMaterial);
          circle.position.copy(targetPosition);
          circle.lookAt(camera.position);
          labelContainer.add(circle);
        });
        
        scene.add(labelContainer);
      }

      // Add mouse event handlers
      function initMouseControls() {
        // Mouse down event
        canvas.addEventListener('mousedown', (event) => {
          isMouseDown = true;
          lastMouseX = event.clientX;
          lastMouseY = event.clientY;
        });

        // Mouse up event
        canvas.addEventListener('mouseup', () => {
          isMouseDown = false;
        });

        // Mouse move event for rotation
        canvas.addEventListener('mousemove', (event) => {
          if (!isMouseDown || !model) return;
          
          const deltaX = event.clientX - lastMouseX;
          const deltaY = event.clientY - lastMouseY;
          
          targetRotation.y += deltaX * mouseSensitivity;
          targetRotation.x += deltaY * mouseSensitivity;
          
          // Clamp rotation
          targetRotation.x = Math.max(-Math.PI/2, Math.min(Math.PI/2, targetRotation.x));
          targetRotation.y = Math.max(-Math.PI, Math.min(Math.PI, targetRotation.y));
          
          lastMouseX = event.clientX;
          lastMouseY = event.clientY;
        });

        // Mouse wheel event for zoom
        canvas.addEventListener('wheel', (event) => {
          if (!model) return;
          
          const zoomDelta = event.deltaY * mouseZoomSpeed;
          const newZoom = camera.position.z + zoomDelta;
          
          // Clamp zoom
          targetZoom = Math.max(minZoom, Math.min(maxZoom, newZoom));
        });
      }

      // Initialize Three.js scene and render
      function initThreeJS() {
        console.log('Initializing Three.js...');
        if (typeof THREE === 'undefined') {
          console.error('Three.js not loaded!');
          return;
        }

        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 0, 3);

        renderer = new THREE.WebGLRenderer({ 
          canvas: canvas, 
          alpha: true,
          antialias: true
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setClearColor(0x000000, 0);

        // Add better lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
        directionalLight.position.set(5, 5, 5);
        scene.add(directionalLight);

        const directionalLight2 = new THREE.DirectionalLight(0xffffff, 0.5);
        directionalLight2.position.set(-5, -5, -5);
        scene.add(directionalLight2);

        console.log('Three.js scene initialized');

        const loader = new THREE.GLTFLoader();
        console.log('Starting to load model...');
        
        loader.load('/static/model.glb', 
          function (gltf) {
            console.log('Model loaded successfully:', gltf);
            model = gltf.scene;
            
            // Center the model
            const box = new THREE.Box3().setFromObject(model);
            const center = box.getCenter(new THREE.Vector3());
            model.position.sub(center);

            // Scale the model appropriately
            const scale = 2.0;  // Increased scale
            model.scale.set(scale, scale, scale);
            
            // Position the model in front of the camera
            model.position.set(0, -1, -2);
            
            scene.add(model);
            console.log('Model added to scene');
            
            // Initialize mouse controls
            initMouseControls();
            
            // Analyze the model and create labels based on the actual model
            analyzeModelViews();
            
            animate();
          }, 
          function (xhr) {
            console.log('Loading progress:', (xhr.loaded / xhr.total * 100) + '%');
          },
          function (error) {
            console.error('Error loading model:', error);
          }
        );
      }

      // Animation loop
      function animate() {
        requestAnimationFrame(animate);
        
        // Smoothly interpolate camera position to target zoom
        if (camera) {
          const zoomDelta = targetZoom - camera.position.z;
          if (Math.abs(zoomDelta) > 0.001) {
            camera.position.z += zoomDelta * zoomInterpolationFactor;
          }
        }
        
        // Smoothly interpolate model rotation
        if (model) {
          const rotationDeltaX = targetRotation.x - model.rotation.x;
          const rotationDeltaY = targetRotation.y - model.rotation.y;
          
          if (Math.abs(rotationDeltaX) > 0.001 || Math.abs(rotationDeltaY) > 0.001) {
            model.rotation.x += rotationDeltaX * rotationInterpolationFactor;
            model.rotation.y += rotationDeltaY * rotationInterpolationFactor;
          }
        }
        
        // Update label container to always face camera
        if (labelContainer) {
          labelContainer.children.forEach(child => {
            if (child instanceof THREE.Sprite) {
              child.lookAt(camera.position);
            }
          });
        }
        
        renderer.render(scene, camera);
      }

      // Button to open the camera
      openBtn.addEventListener('click', () => {
        openBtn.style.display = 'none';
        initCamera();
        initThreeJS();
      });

      // Add event listener for capture button
      captureBtn.addEventListener('click', captureAndAnalyze);

      // Handle window resize
      window.addEventListener('resize', () => {
        if (camera && renderer) {
          camera.aspect = window.innerWidth / window.innerHeight;
          camera.updateProjectionMatrix();
          renderer.setSize(window.innerWidth, window.innerHeight);
        }
      });
    });
  </script>
</body>
</html>
