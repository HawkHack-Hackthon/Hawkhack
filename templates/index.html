<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>3D Model in Camera</title>
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Space+Mono:ital,wght@0,400;0,700;1,400;1,700&display=swap');

    body, html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      font-family: 'Space Mono', monospace;
    }

    /* Common button styles */
    .btn-common {
      padding: 12px 24px;
      border: none;
      border-radius: 12px;
      font-size: 16px;
      font-family: 'Space Mono', monospace;
      color: white;
      cursor: pointer;
      transition: all 0.3s ease;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    .btn-common:hover {
      transform: translateY(-2px);
      box-shadow: 0 0 15px rgba(33, 150, 243, 0.6);
    }

    #openBtn {
      position: absolute;
      top: 20px;
      left: 20px;
      z-index: 2;
      background: #2196F3;
    }

    #captureBtn {
      position: absolute;
      top: 20px;
      left: 150px;
      z-index: 2;
      background: #2196F3;
      display: none;
    }

    #backgroundToggle {
      position: absolute;
      top: 20px;
      right: 20px;
      z-index: 2;
      background: #2196F3;
    }

    #resultText {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      z-index: 2;
      color: white;
      font-size: 28px;
      font-weight: bold;
      text-align: center;
      font-family: 'Space Mono', monospace;
      text-shadow: 2px 2px 8px rgba(0, 0, 0, 0.5),
                   0 0 20px rgba(33, 150, 243, 0.4);
      background: rgba(0, 0, 0, 0.4);
      padding: 10px 20px;
      border-radius: 8px;
      display: none;
    }

    .background-options {
      position: absolute;
      top: 70px;
      right: 20px;
      z-index: 2;
      display: none;
      background: white;
      border-radius: 12px;
      padding: 10px;
      box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
      font-family: 'Space Mono', monospace;
    }

    .background-option {
      padding: 10px 20px;
      cursor: pointer;
      border-radius: 8px;
      margin: 4px 0;
      transition: all 0.3s ease;
    }

    .background-option:hover {
      background: rgba(33, 150, 243, 0.1);
      color: #2196F3;
    }

    .background-option.active {
      background: rgba(33, 150, 243, 0.2);
      color: #2196F3;
    }

    /* Apply common button class */
    #openBtn, #captureBtn, #backgroundToggle {
      composes: btn-common;
    }

    #cameraFeed {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      object-fit: cover;
      z-index: 0;
    }
    #threeCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 1;
      touch-action: none;
    }
    .explanation-section {
      position: absolute;
      bottom: 0;
      left: 0;
      width: 100%;
      background: rgba(0, 0, 0, 0.8);
      color: white;
      padding: 20px;
      display: flex;
      gap: 20px;
      z-index: 2;
      transition: transform 0.3s ease-in-out;
    }
    
    .explanation-section.collapsed {
      transform: translateY(calc(100% - 40px));
    }
    
    .toggle-explanation {
      position: absolute;
      top: -40px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.8);
      color: white;
      border: none;
      padding: 8px 20px;
      border-radius: 8px 8px 0 0;
      cursor: pointer;
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 14px;
    }
    
    .toggle-explanation:hover {
      background: rgba(0, 0, 0, 0.9);
    }
    
    .toggle-explanation .arrow {
      transition: transform 0.3s ease;
      display: inline-block;
    }
    
    .explanation-section.collapsed .toggle-explanation .arrow {
      transform: rotate(180deg);
    }
    
    .explanation-left {
      flex: 1;
      padding: 20px;
      background: rgba(255, 255, 255, 0.1);
      border-radius: 8px;
    }
    
    .explanation-right {
      flex: 1;
      padding: 20px;
      background: rgba(255, 255, 255, 0.1);
      border-radius: 8px;
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
      gap: 15px;
      overflow-y: auto;
      max-height: 300px;
    }
    .video-item {
      cursor: pointer;
      transition: transform 0.2s;
    }
    .video-item:hover {
      transform: scale(1.05);
    }
    .video-thumbnail {
      width: 100%;
      border-radius: 4px;
    }
    .video-title {
      font-size: 14px;
      margin-top: 8px;
      color: white;
    }
    .play-button {
      background: #2196F3;
      color: white;
      border: none;
      padding: 8px 16px;
      border-radius: 4px;
      cursor: pointer;
      margin-top: 10px;
      display: flex;
      align-items: center;
      gap: 8px;
    }
    .play-button:hover {
      background: #1976D2;
    }
    .explanation-points {
      margin-top: 15px;
      line-height: 1.6;
    }
    .explanation-points li {
      margin-bottom: 8px;
    }
  </style>
  <!-- Load Three.js and its dependencies -->
  <script src="/static/js/three.min.js"></script>
  <script src="/static/js/GLTFLoader.js"></script>
  <!-- Add MediaPipe hand tracking -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils@0.3/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils@0.3/drawing_utils.js"></script>
</head>
<body>
  <video id="cameraFeed" autoplay muted playsinline></video>
  <canvas id="threeCanvas"></canvas>
  <button id="openBtn" class="btn-common">Open Camera</button>
  <button id="captureBtn" class="btn-common">Take Photo</button>
  <button id="backgroundToggle" class="btn-common">Change Background</button>
  <div class="background-options">
    <div class="background-option" data-bg="webcam">Webcam</div>
    <div class="background-option" data-bg="white">White</div>
    <div class="background-option" data-bg="black">Black</div>
  </div>
  <div id="resultText"></div>
  <div class="explanation-section">
    <button class="toggle-explanation">
      <span class="arrow">â–¼</span>
      <span class="text">Explanation & Videos</span>
    </button>
    <div class="explanation-left">
      <h3>Heart Diagram Explanation</h3>
      <button class="play-button" onclick="speakExplanation()">
        <span>ðŸ”Š Play Explanation</span>
      </button>
      <ul class="explanation-points">
        <li>The heart is a muscular organ that pumps blood throughout the body</li>
        <li>It has four chambers: two atria and two ventricles</li>
        <li>The right side pumps blood to the lungs for oxygenation</li>
        <li>The left side pumps oxygenated blood to the body</li>
        <li>Valves prevent backflow of blood</li>
        <li>The heart beats about 100,000 times per day</li>
      </ul>
    </div>
    <div class="explanation-right" id="youtubeVideos">
      <!-- YouTube videos will be loaded here -->
    </div>
  </div>

  <script>
    // Wait for Three.js to load
    window.addEventListener('load', function() {
      console.log('Three.js loaded:', typeof THREE !== 'undefined');
      
      const video = document.getElementById('cameraFeed');
      const canvas = document.getElementById('threeCanvas');
      const openBtn = document.getElementById('openBtn');
      const captureBtn = document.getElementById('captureBtn');
      const resultText = document.getElementById('resultText');
      const backgroundToggle = document.getElementById('backgroundToggle');
      const backgroundOptions = document.querySelector('.background-options');
      const backgroundOptionElements = document.querySelectorAll('.background-option');
      
      const GEMINI_API_KEY = 'AIzaSyBHVWfY-js7KnjSQGuRe_Q0S2Tfu6W_cLI';

      let scene, camera, renderer, model;
      let hands;
      let lastPinchDistance = 0;
      let lastHandPosition = null;
      let targetZoom = 3;
      let targetRotation = { x: 0, y: 0 };
      const minZoom = 2.0;
      const maxZoom = 6.0;
      const zoomSpeed = 0.1;
      const zoomInterpolationFactor = 0.08;
      const rotationInterpolationFactor = 0.1;
      const rotationSensitivity = 3.0;
      let isHandTrackingActive = false;
      
      // Add label containers
      let labels = [];
      let labelContainer;
      
      // Add smoothing buffers
      const positionBuffer = [];
      const rotationBuffer = [];
      const bufferSize = 3;
      const movementThreshold = 0.005;

      // Add mouse control variables
      let isMouseDown = false;
      let lastMouseX = 0;
      let lastMouseY = 0;
      let mouseSensitivity = 0.01;
      let mouseZoomSpeed = 0.1;
      let isRightMouseDown = false;
      let lastRightMouseX = 0;
      let lastRightMouseY = 0;
      let mouseRotationSpeed = 0.005;
      let mousePanSpeed = 0.005;
      let isTrackpad = false;
      let lastWheelTime = 0;
      let wheelDelta = 0;

      let currentBackground = 'webcam';
      let isCameraActive = false;
      
      // Function to set background
      function setBackground(type) {
        currentBackground = type;
        
        // Update active state of options
        backgroundOptionElements.forEach(option => {
          option.classList.toggle('active', option.dataset.bg === type);
        });
        
        switch(type) {
          case 'webcam':
            video.style.display = 'block';
            canvas.style.backgroundColor = 'transparent';
            break;
          case 'white':
            video.style.display = 'none';
            canvas.style.backgroundColor = '#ffffff';
            break;
          case 'black':
            video.style.display = 'none';
            canvas.style.backgroundColor = '#000000';
            break;
        }
        
        // Update text color based on background
        if (type === 'white') {
          resultText.style.color = 'black';
          resultText.style.textShadow = '2px 2px 4px rgba(0, 0, 0, 0.2)';
        } else {
          resultText.style.color = 'white';
          resultText.style.textShadow = '2px 2px 4px rgba(0, 0, 0, 0.5)';
        }
        
        // Close options menu
        backgroundOptions.style.display = 'none';
      }

      // Toggle background options menu
      backgroundToggle.addEventListener('click', () => {
        backgroundOptions.style.display = 
          backgroundOptions.style.display === 'none' ? 'block' : 'none';
      });

      // Handle background option selection
      backgroundOptionElements.forEach(option => {
        option.addEventListener('click', () => {
          const bgType = option.dataset.bg;
          if (bgType === 'webcam' && !isCameraActive) {
            initCamera();
          }
          setBackground(bgType);
        });
      });

      // Function to capture model view
      function captureModelView(angle) {
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = 800;
        tempCanvas.height = 600;
        const tempRenderer = new THREE.WebGLRenderer({ 
          canvas: tempCanvas,
          alpha: true,
          antialias: true
        });
        
        // Create temporary camera
        const tempCamera = new THREE.PerspectiveCamera(75, 800/600, 0.1, 1000);
        tempCamera.position.set(0, 0, 5);
        
        // Rotate model for the view
        const originalRotation = model.rotation.clone();
        model.rotation.set(0, angle * Math.PI / 180, 0);
        
        // Render the view
        tempRenderer.render(scene, tempCamera);
        
        // Reset model rotation
        model.rotation.copy(originalRotation);
        
        return tempCanvas.toDataURL('image/jpeg');
      }

      // Function to create text label with simplified styling
      function createTextLabel(text, position, color = 0x000000) {
        const canvas = document.createElement('canvas');
        const context = canvas.getContext('2d');
        canvas.width = 300;
        canvas.height = 80;
        
        // Simple background
        context.fillStyle = 'rgba(0, 0, 0, 0.5)';
        context.fillRect(0, 0, canvas.width, canvas.height);
        
        // Simple text styling
        context.font = '20px Arial';
        context.fillStyle = '#ffffff';
        context.textAlign = 'left';
        context.fillText(text, 15, canvas.height/2 + 10);
        
        const texture = new THREE.CanvasTexture(canvas);
        const material = new THREE.SpriteMaterial({ 
          map: texture,
          transparent: true,
          opacity: 0.8
        });
        const sprite = new THREE.Sprite(material);
        
        sprite.position.copy(position);
        sprite.scale.set(1.2, 0.3, 1);
        sprite.userData = { 
          text: text,
          originalColor: color
        };
        
        return sprite;
      }

      // Function to create connecting line with simplified styling
      function createConnectingLine(start, end, color = 0x000000) {
        const material = new THREE.LineBasicMaterial({ 
          color: color,
          linewidth: 3,
          transparent: true,
          opacity: 0.8
        });
        const points = [];
        points.push(start);
        points.push(end);
        const geometry = new THREE.BufferGeometry().setFromPoints(points);
        const line = new THREE.Line(geometry, material);
        return line;
      }

      // Function to analyze model views
      async function analyzeModelViews() {
        try {
          // Capture front and side views
          const frontView = captureModelView(0);
          const sideView = captureModelView(90);
          
          // Prepare the request to Gemini API
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [{
                parts: [
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: frontView.split(',')[1]
                    }
                  },
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: sideView.split(',')[1]
                    }
                  },
                  {
                    text: "These are front and side views of a 3D brain model. Analyze the brain structure and provide 5-6 labels describing different parts of the brain. For each label, specify its position in degrees (0-360) around the model. Return ONLY a valid JSON object in this exact format: {\"labels\": [{\"text\": \"label name\", \"angle\": \"angle in degrees\"}, ...]}. Do not include any other text or explanation."
                  }
                ]
              }]
            })
          });
          
          const data = await response.json();
          if (data.candidates && data.candidates[0].content.parts[0].text) {
            const result = data.candidates[0].content.parts[0].text;
            try {
              // Clean the response to ensure it's valid JSON
              const jsonStart = result.indexOf('{');
              const jsonEnd = result.lastIndexOf('}') + 1;
              const jsonStr = result.substring(jsonStart, jsonEnd);
              
              const labelsData = JSON.parse(jsonStr).labels;
              create3DLabels(labelsData);
            } catch (e) {
              console.error('Error parsing labels:', e);
              console.log('Raw response:', result);
            }
          }
        } catch (error) {
          console.error('Error analyzing model views:', error);
        }
      }

      // Initialize MediaPipe Hands
      function initHandTracking() {
        console.log('Initializing hand tracking...');
        hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4.1646424915/${file}`;
          }
        });
        
        hands.setOptions({
          maxNumHands: 1,  // Changed to 1 hand for better focus
          modelComplexity: 0,  // Changed to 0 for faster processing
          minDetectionConfidence: 0.7,  // Increased confidence threshold
          minTrackingConfidence: 0.7    // Increased confidence threshold
        });

        hands.onResults(onHandResults);
        console.log('Hand tracking initialized');
      }

      // Process hand tracking results with enhanced zoom
      function onHandResults(results) {
        if (!results.multiHandLandmarks) {
          if (isHandTrackingActive) {
            console.log('Hand lost, maintaining last position');
            isHandTrackingActive = false;
          }
          return;
        }

        if (!model) {
          console.log('Model not loaded yet');
          return;
        }

        isHandTrackingActive = true;
        const landmarks = results.multiHandLandmarks[0];
        
        if (landmarks) {
          const thumbTip = landmarks[4];
          const indexTip = landmarks[8];
          const palmBase = landmarks[0];
          
          // Enhanced pinch zoom with better sensitivity
          const pinchDistance = Math.sqrt(
            Math.pow(thumbTip.x - indexTip.x, 2) +
            Math.pow(thumbTip.y - indexTip.y, 2)
          );

          if (lastPinchDistance === 0) {
            lastPinchDistance = pinchDistance;
            lastHandPosition = { x: palmBase.x, y: palmBase.y };
            return;
          }

          // Calculate zoom factor with enhanced sensitivity
          const zoomFactor = lastPinchDistance / pinchDistance;
          if (Math.abs(1 - zoomFactor) > 0.03) {  // Reduced threshold for more responsive zoom
          const newTargetZoom = camera.position.z * zoomFactor;
          targetZoom = Math.max(minZoom, Math.min(maxZoom, newTargetZoom));
          }
          lastPinchDistance = pinchDistance;

          // Handle hand rotation with smoothing
          if (lastHandPosition) {
            // Calculate hand movement delta with increased sensitivity
            const deltaX = (palmBase.x - lastHandPosition.x) * rotationSensitivity;
            const deltaY = (palmBase.y - lastHandPosition.y) * rotationSensitivity;

            // Only update if movement is significant
            if (Math.abs(deltaX) > movementThreshold || Math.abs(deltaY) > movementThreshold) {
              // Add to rotation buffer
              rotationBuffer.push({ x: deltaX, y: deltaY });
              if (rotationBuffer.length > bufferSize) {
                rotationBuffer.shift();
              }

              // Calculate average rotation with reduced smoothing
              const avgRotation = rotationBuffer.reduce((acc, curr) => {
                return { x: acc.x + curr.x, y: acc.y + curr.y };
              }, { x: 0, y: 0 });
              
              const avgDeltaX = avgRotation.x / rotationBuffer.length;
              const avgDeltaY = avgRotation.y / rotationBuffer.length;

              // Update target rotation with increased movement
              targetRotation.y += avgDeltaX * 1.5;  // Increased rotation multiplier
              targetRotation.x += avgDeltaY * 1.5;  // Increased rotation multiplier

            // Clamp rotation to reasonable bounds
            targetRotation.x = Math.max(-Math.PI/2, Math.min(Math.PI/2, targetRotation.x));
            targetRotation.y = Math.max(-Math.PI, Math.min(Math.PI, targetRotation.y));
            }
          }

          lastHandPosition = { x: palmBase.x, y: palmBase.y };
        }
      }

      // Function to capture photo and send to Gemini
      async function captureAndAnalyze() {
        try {
          // Create a temporary canvas to capture the video frame
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          const ctx = tempCanvas.getContext('2d');
          ctx.drawImage(video, 0, 0);
          
          // Convert canvas to base64
          const imageData = tempCanvas.toDataURL('image/jpeg');
          
          // Prepare the request to Gemini API
          const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${GEMINI_API_KEY}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [{
                parts: [
                  {
                    inline_data: {
                      mime_type: "image/jpeg",
                      data: imageData.split(',')[1]
                    }
                  },
                  {
                    text: "Identify the main object in this image. Return ONLY a single word, nothing else. For example, if you see a heart, just return 'heart'. If you see a brain, just return 'brain'. Do not include any punctuation, explanations, or additional text."
                  }
                ]
              }]
            })
          });
          
          const data = await response.json();
          if (data.candidates && data.candidates[0].content.parts[0].text) {
            const identifiedObject = data.candidates[0].content.parts[0].text.trim().toLowerCase();
            resultText.textContent = identifiedObject;
            resultText.style.display = 'block';
            
            // Load the corresponding 3D model
            await loadModel(identifiedObject);
            
            // Update content based on the identified object
            updateContent(identifiedObject);
          }
        } catch (error) {
          console.error('Error analyzing image:', error);
          resultText.textContent = 'Error analyzing image';
          resultText.style.display = 'block';
        }
      }

      // Function to load the appropriate 3D model
      async function loadModel(objectName) {
        try {
          // Remove existing model if any
          if (model) {
            scene.remove(model);
          }
          
          // Load the new model
          const loader = new THREE.GLTFLoader();
          const modelPath = `/static/models/${objectName}.glb`;
          
          return new Promise((resolve, reject) => {
            loader.load(modelPath, 
              function (gltf) {
                console.log('Model loaded successfully:', gltf);
                model = gltf.scene;
                
                // Center the model
                const box = new THREE.Box3().setFromObject(model);
                const center = box.getCenter(new THREE.Vector3());
                model.position.sub(center);

                // Scale the model appropriately
                const scale = 2.0;
                model.scale.set(scale, scale, scale);
                
                // Position the model in front of the camera
                model.position.set(0, -1, -2);
                
                scene.add(model);
                console.log('Model added to scene');
                
                // Analyze the model and create labels
                analyzeModelViews();
                resolve();
              },
              function (xhr) {
                console.log('Loading progress:', (xhr.loaded / xhr.total * 100) + '%');
              },
              function (error) {
                console.error('Error loading model:', error);
                reject(error);
              }
            );
          });
        } catch (error) {
          console.error('Error in loadModel:', error);
          throw error;
        }
      }

      // Function to update content based on the identified object
      function updateContent(objectName) {
        // Update explanation section
        const explanationSection = document.querySelector('.explanation-left');
        const explanationTitle = explanationSection.querySelector('h3');
        const explanationPoints = explanationSection.querySelector('.explanation-points');
        
        // Update title
        explanationTitle.textContent = `${objectName.charAt(0).toUpperCase() + objectName.slice(1)} Diagram Explanation`;
        
        // Update explanation points based on the object
        const explanations = {
          'heart': [
            'The heart is a muscular organ that pumps blood throughout the body',
            'It has four chambers: two atria and two ventricles',
            'The right side pumps blood to the lungs for oxygenation',
            'The left side pumps oxygenated blood to the body',
            'Valves prevent backflow of blood',
            'The heart beats about 100,000 times per day'
          ],
          'brain': [
            'The brain is the control center of the nervous system',
            'It consists of three main parts: cerebrum, cerebellum, and brainstem',
            'The cerebrum controls voluntary actions and cognitive functions',
            'The cerebellum coordinates movement and balance',
            'The brainstem controls basic life functions',
            'The brain contains billions of neurons that communicate through electrical signals'
          ],
          'lung': [
            'Lungs are the primary organs of the respiratory system',
            'They exchange oxygen and carbon dioxide with the blood',
            'The right lung has three lobes, while the left has two',
            'The diaphragm helps in breathing by expanding and contracting',
            'Lungs are protected by the rib cage',
            'The surface area of the lungs is about the size of a tennis court'
          ]
          // Add more objects and their explanations as needed
        };
        
        // Set default explanation if object not found
        const objectExplanations = explanations[objectName] || [
          'This is a 3D model of the identified object',
          'Use the mouse to rotate and zoom',
          'Click on labels to learn more about different parts',
          'Watch the related videos for more information'
        ];
        
        // Update explanation points
        explanationPoints.innerHTML = objectExplanations.map(point => 
          `<li>${point}</li>`
        ).join('');
        
        // Update YouTube search query
        fetchYouTubeVideos(objectName);
      }

      // Modified function to fetch YouTube videos based on the identified object
      async function fetchYouTubeVideos(objectName) {
        const query = `${objectName} diagram explanation`;
        const apiKey = 'AIzaSyBiuZcFHVQO_mGOVuo_W6NBIOY9xnWSZ3Q';
        const maxResults = 6;
        
        try {
          const response = await fetch(
            `https://www.googleapis.com/youtube/v3/search?` +
            `part=snippet&` +
            `q=${encodeURIComponent(query)}&` +
            `maxResults=${maxResults}&` +
            `type=video&` +
            `videoEmbeddable=true&` +
            `key=${apiKey}`
          );
          
          if (!response.ok) {
            const errorData = await response.json();
            console.error('YouTube API error details:', errorData);
            throw new Error(`YouTube API error: ${response.status} - ${errorData.error?.message || 'Unknown error'}`);
          }
          
          const data = await response.json();
          const videosContainer = document.getElementById('youtubeVideos');
          videosContainer.innerHTML = '';
          
          if (!data.items || !Array.isArray(data.items)) {
            throw new Error('Invalid YouTube API response format');
          }
          
          data.items.forEach(item => {
            if (!item.id || !item.id.videoId || !item.snippet) {
              console.warn('Skipping invalid video item:', item);
              return;
            }
            
            const videoId = item.id.videoId;
            const thumbnail = item.snippet.thumbnails?.medium?.url || '';
            const title = item.snippet.title || 'Untitled';
            
            const videoElement = document.createElement('div');
            videoElement.className = 'video-item';
            videoElement.innerHTML = `
              <img src="${thumbnail}" alt="${title}" class="video-thumbnail">
              <div class="video-title">${title}</div>
            `;
            
            videoElement.addEventListener('click', () => {
              window.open(`https://www.youtube.com/watch?v=${videoId}`, '_blank');
            });
            
            videosContainer.appendChild(videoElement);
          });
        } catch (error) {
          console.error('Error fetching YouTube videos:', error);
          const videosContainer = document.getElementById('youtubeVideos');
          videosContainer.innerHTML = `
            <div class="error-message">
              <p>Unable to load videos. Please try again later.</p>
              <p>Error: ${error.message}</p>
            </div>
          `;
        }
      }

      // Make speakExplanation globally accessible
      window.speakExplanation = function() {
        const explanation = document.querySelector('.explanation-points').textContent;
        const speech = new SpeechSynthesisUtterance(explanation);
        speech.rate = 1;
        speech.pitch = 1;
        window.speechSynthesis.speak(speech);
      };

      // Initialize Three.js scene and render
      function initThreeJS() {
        console.log('Initializing Three.js...');
        if (typeof THREE === 'undefined') {
          console.error('Three.js not loaded!');
          return;
        }

        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 0, 3);

        renderer = new THREE.WebGLRenderer({ 
          canvas: canvas, 
          alpha: true,
          antialias: true
        });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setClearColor(0x000000, 0);

        // Add better lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);

        const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
        directionalLight.position.set(5, 5, 5);
        scene.add(directionalLight);

        const directionalLight2 = new THREE.DirectionalLight(0xffffff, 0.5);
        directionalLight2.position.set(-5, -5, -5);
        scene.add(directionalLight2);

        console.log('Three.js scene initialized');
        
        // Initialize mouse controls
        initMouseControls();
        
        // Start animation loop
        animate();
      }

      // Animation loop
      function animate() {
        requestAnimationFrame(animate);
        
        if (model) {
          // Smooth zoom interpolation
          const zoomDelta = targetZoom - camera.position.z;
          if (Math.abs(zoomDelta) > 0.001) {
            camera.position.z += zoomDelta * zoomInterpolationFactor;
          }
          
          // Smooth rotation interpolation
          const rotationDeltaX = targetRotation.x - model.rotation.x;
          const rotationDeltaY = targetRotation.y - model.rotation.y;
          
          if (Math.abs(rotationDeltaX) > 0.001 || Math.abs(rotationDeltaY) > 0.001) {
            model.rotation.x += rotationDeltaX * rotationInterpolationFactor;
            model.rotation.y += rotationDeltaY * rotationInterpolationFactor;
          }
        }
        
        // Update label container to always face camera
        if (labelContainer) {
          labelContainer.children.forEach(child => {
            if (child instanceof THREE.Sprite) {
              child.lookAt(camera.position);
            }
          });
        }
        
        renderer.render(scene, camera);
      }

      // Button to open the camera
      openBtn.addEventListener('click', () => {
        openBtn.style.display = 'none';
        initCamera();
        initThreeJS();
        setBackground('webcam');
      });

      // Add event listener for capture button
      captureBtn.addEventListener('click', captureAndAnalyze);

      // Handle window resize
      window.addEventListener('resize', () => {
        if (camera && renderer) {
          camera.aspect = window.innerWidth / window.innerHeight;
          camera.updateProjectionMatrix();
          renderer.setSize(window.innerWidth, window.innerHeight);
        }
      });

      // Initialize with black background
      setBackground('black');

      // Initialize the camera feed
      async function initCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
              width: 640,
              height: 480,
              facingMode: 'user'
            } 
          });
          video.srcObject = stream;
          isCameraActive = true;
          
          // Wait for video to be ready
          video.onloadedmetadata = () => {
            console.log('Video stream ready');
            // Show capture button
            captureBtn.style.display = 'block';
            // Initialize hand tracking after camera is ready
            initHandTracking();
            
            // Start sending frames to MediaPipe
            const camera = new Camera(video, {
              onFrame: async () => {
                try {
                  await hands.send({ image: video });
                } catch (error) {
                  console.error('Error processing hand tracking:', error);
                }
              },
              width: 640,
              height: 480
            });
            camera.start();
            console.log('Camera tracking started');
          };
        } catch (err) {
          console.error('Camera error:', err);
          // If camera fails, switch to black background
          setBackground('black');
        }
      }

      // Function to create arrow helper
      function createArrowHelper(start, end, color = 0xffffff) {
        const dir = new THREE.Vector3().subVectors(end, start).normalize();
        const length = start.distanceTo(end);
        const arrowHelper = new THREE.ArrowHelper(dir, start, length, color, length * 0.2, length * 0.1);
        return arrowHelper;
      }

      // Function to create 3D labels based on analysis
      function create3DLabels(labelsData) {
        if (!model) return;
        
        // Remove existing labels
        if (labelContainer) {
          scene.remove(labelContainer);
        }
        
        labelContainer = new THREE.Group();
        
        // Get model bounding box
        const box = new THREE.Box3().setFromObject(model);
        const size = box.getSize(new THREE.Vector3());
        const center = box.getCenter(new THREE.Vector3());
        
        // Define label positions around the model
        const radius = size.x * 1.2;  // Distance from center
        
        // Create labels and connecting lines based on the analyzed data
        labelsData.forEach(label => {
          // Calculate position around the model
          const angleRad = parseFloat(label.angle) * Math.PI / 180;
          const x = center.x + radius * Math.cos(angleRad);
          const z = center.z + radius * Math.sin(angleRad);
          const y = center.y;  // Default height, can be adjusted based on model
          
          const labelPosition = new THREE.Vector3(x, y, z);
          const targetPosition = new THREE.Vector3(
            center.x + size.x * 0.3 * Math.cos(angleRad),
            y,
            center.z + size.z * 0.3 * Math.sin(angleRad)
          );
          
          // Create text label
          const textLabel = createTextLabel(label.text, labelPosition);
          labelContainer.add(textLabel);
          
          // Create connecting line
          const line = createConnectingLine(targetPosition, labelPosition);
          labelContainer.add(line);
          
          // Add small circle at the model connection point
          const circleGeometry = new THREE.CircleGeometry(0.05, 32);
          const circleMaterial = new THREE.MeshBasicMaterial({ color: 0x000000 });
          const circle = new THREE.Mesh(circleGeometry, circleMaterial);
          circle.position.copy(targetPosition);
          circle.lookAt(camera.position);
          labelContainer.add(circle);
        });
        
        scene.add(labelContainer);
      }

      // Add mouse event handlers
      function initMouseControls() {
        // Detect if using trackpad
        canvas.addEventListener('wheel', (event) => {
          const now = Date.now();
          if (now - lastWheelTime < 50) {
            isTrackpad = true;
          }
          lastWheelTime = now;
          wheelDelta = event.deltaY;
        });
        
        // Left mouse button for rotation
        canvas.addEventListener('mousedown', (event) => {
          if (event.button === 0) { // Left mouse button
            isMouseDown = true;
            lastMouseX = event.clientX;
            lastMouseY = event.clientY;
            canvas.style.cursor = 'grabbing';
          } else if (event.button === 2) { // Right mouse button
            isRightMouseDown = true;
            lastRightMouseX = event.clientX;
            lastRightMouseY = event.clientY;
            canvas.style.cursor = 'move';
          }
        });

        // Mouse up event
        canvas.addEventListener('mouseup', (event) => {
          if (event.button === 0) {
            isMouseDown = false;
            canvas.style.cursor = 'grab';
          } else if (event.button === 2) {
            isRightMouseDown = false;
            canvas.style.cursor = 'default';
          }
        });

        // Mouse move event for rotation and panning
        canvas.addEventListener('mousemove', (event) => {
          if (!model) return;
          
          if (isMouseDown) {
            // Rotation with trackpad support
            const deltaX = event.clientX - lastMouseX;
            const deltaY = event.clientY - lastMouseY;
            
            // Adjust sensitivity based on whether using trackpad
            const rotationMultiplier = isTrackpad ? 0.5 : 1;
            
            targetRotation.y += deltaX * mouseRotationSpeed * rotationMultiplier;
            targetRotation.x += deltaY * mouseRotationSpeed * rotationMultiplier;
            
            // Clamp rotation
            targetRotation.x = Math.max(-Math.PI/2, Math.min(Math.PI/2, targetRotation.x));
            targetRotation.y = Math.max(-Math.PI, Math.min(Math.PI, targetRotation.y));
            
            lastMouseX = event.clientX;
            lastMouseY = event.clientY;
          } else if (isRightMouseDown) {
            // Panning with trackpad support
            const deltaX = event.clientX - lastRightMouseX;
            const deltaY = event.clientY - lastRightMouseY;
            
            // Adjust sensitivity based on whether using trackpad
            const panMultiplier = isTrackpad ? 0.5 : 1;
            
            // Calculate pan direction in world space
            const panX = deltaX * mousePanSpeed * panMultiplier;
            const panY = -deltaY * mousePanSpeed * panMultiplier; // Invert Y for natural movement
            
            // Apply pan to model position
            model.position.x += panX;
            model.position.y += panY;
            
            lastRightMouseX = event.clientX;
            lastRightMouseY = event.clientY;
          }
        });
        
        // Enhanced mouse wheel event for zoom with trackpad support
        canvas.addEventListener('wheel', (event) => {
          if (!model) return;
          
          // Calculate zoom direction and amount
          const zoomDirection = Math.sign(event.deltaY);
          
          // Adjust zoom speed based on whether using trackpad
          const zoomMultiplier = isTrackpad ? 0.5 : 1;
          const zoomAmount = zoomDirection * mouseZoomSpeed * zoomMultiplier;
          
          // Calculate new zoom target
          const newZoom = camera.position.z + zoomAmount;
          
          // Clamp zoom
          targetZoom = Math.max(minZoom, Math.min(maxZoom, newZoom));
          
          // Prevent default scroll behavior
          event.preventDefault();
        });
        
        // Prevent context menu on right click
        canvas.addEventListener('contextmenu', (event) => {
          event.preventDefault();
        });
        
        // Set initial cursor style
        canvas.style.cursor = 'grab';
      }

      // Add toggle functionality for explanation section
      const explanationSection = document.querySelector('.explanation-section');
      const toggleButton = document.querySelector('.toggle-explanation');
      
      toggleButton.addEventListener('click', () => {
        explanationSection.classList.toggle('collapsed');
      });
      
      // Start with explanation section collapsed
      explanationSection.classList.add('collapsed');
    });
  </script>
</body>
</html>
